{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.snowpark.functions as F\n",
    "from snowflake.snowpark.functions import udf\n",
    "from snowflake.snowpark.types import VariantType\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.types import StructType, StructField, FloatType\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "    \"account\": os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    \"user\": os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    \"password\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "    \"schema\": os.getenv(\"SNOWFLAKE_SCHEMA\"),\n",
    "    \"database\": os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "    \"role\": os.getenv(\"SNOWFLAKE_ROLE\"),\n",
    "    \"warehouse\": os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "}\n",
    "\n",
    "session = Session.builder.configs(connection_parameters).create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Database and schema: \"MLOPS\".\"ADVERTISING\"\n",
      "Current Warehouse: \"COMPUTE_WH\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Current Database and schema: {session.get_fully_qualified_current_schema()}\")\n",
    "print(f\"Current Warehouse: {session.get_current_warehouse()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_df = session.table(\"ADVERTISING\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Stage area ML_MODELS successfully created.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stage for storing the trained model without specifying file format\n",
    "session.sql(\"\"\"\n",
    "CREATE OR REPLACE STAGE ml_models\n",
    "\"\"\").collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\n",
    "    f\"ALTER WAREHOUSE {session.get_current_warehouse()[1:-1]} SET WAREHOUSE_SIZE=LARGE;\"\n",
    ").collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Function TRAIN successfully created.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "create_procedure_sql = \"\"\"\n",
    "CREATE OR REPLACE PROCEDURE train()\n",
    "  RETURNS VARIANT\n",
    "  LANGUAGE PYTHON\n",
    "  RUNTIME_VERSION = 3.11\n",
    "  PACKAGES = ('snowflake-snowpark-python', 'scikit-learn', 'joblib')\n",
    "  HANDLER = 'main'\n",
    "AS $$\n",
    "import os\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from joblib import dump\n",
    "\n",
    "def main(session):\n",
    "  df = session.table('ADVERTISING').to_pandas()\n",
    "  X = df[['TV', 'RADIO', 'NEWSPAPER']]\n",
    "  y = df['SALES']\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "  \n",
    "  numeric_features = ['TV', 'RADIO', 'NEWSPAPER']\n",
    "  numeric_transformer = Pipeline(steps=[('poly', PolynomialFeatures()), ('scaler', StandardScaler())])\n",
    "  preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numeric_features)])\n",
    "  pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', LinearRegression(n_jobs=-1))])\n",
    "\n",
    "  # Define parameter grid for GridSearchCV\n",
    "  param_grid = {\n",
    "      'preprocessor__num__poly__degree': [2, 3],\n",
    "      'classifier__fit_intercept': [True, False]\n",
    "  }\n",
    "\n",
    "  model = GridSearchCV(pipeline, param_grid=param_grid, n_jobs=-1, cv=10)\n",
    "  model.fit(X_train, y_train)\n",
    "  \n",
    "  model_file = os.path.join('/tmp', 'model.joblib')\n",
    "  dump(model, model_file)\n",
    "  session.file.put(model_file, \"@ml_models\", overwrite=True)\n",
    "  \n",
    "  return {\"Best parameters\": model.best_params_, \"R2 score on Train\": model.score(X_train, y_train), \"R2 score on Test\": model.score(X_test, y_test)}\n",
    "$$;\n",
    "\"\"\"\n",
    "session.sql(create_procedure_sql).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\n",
    "    f\"ALTER WAREHOUSE {session.get_current_warehouse()[1:-1]} SET WAREHOUSE_SIZE=XSMALL;\"\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "|\"TRAIN\"                                       |\n",
      "------------------------------------------------\n",
      "|{                                             |\n",
      "|  \"Best parameters\": {                        |\n",
      "|    \"classifier__fit_intercept\": true,        |\n",
      "|    \"preprocessor__num__poly__degree\": 2      |\n",
      "|  },                                          |\n",
      "|  \"R2 score on Test\": 9.533174341074796e-01,  |\n",
      "|  \"R2 score on Train\": 9.288133512730626e-01  |\n",
      "|}                                             |\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute the stored procedure to train the model\n",
    "session.sql(\"CALL train()\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.udf.UserDefinedFunction at 0x297cf5e8f10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snowflake.snowpark.functions import udf\n",
    "import snowflake.snowpark.types as T\n",
    "\n",
    "# Define the UDF function\n",
    "def predict_sales(tv: float, radio: float, newspaper: float) -> float:\n",
    "    import os\n",
    "    import sys\n",
    "    from joblib import load\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Specify the import directory for the Snowflake stage files\n",
    "    IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n",
    "    import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n",
    "    model_path = os.path.join(import_dir, 'model.joblib')\n",
    "    model = load(model_path)\n",
    "    input_data = pd.DataFrame([[tv, radio, newspaper]], columns=['TV', 'RADIO', 'NEWSPAPER'])\n",
    "    prediction = model.predict(input_data)[0]\n",
    "    \n",
    "    return float(prediction)\n",
    "\n",
    "# Register the UDF\n",
    "session.udf.register(\n",
    "    func=predict_sales, \n",
    "    name=\"predict_sales\", \n",
    "    stage_location=\"@ml_models\",\n",
    "    input_types=[T.FloatType(), T.FloatType(), T.FloatType()],\n",
    "    return_type=T.FloatType(),\n",
    "    replace=True, \n",
    "    is_permanent=True, \n",
    "    imports=['@ml_models/model.joblib'],\n",
    "    packages=['scikit-learn', 'pandas', 'joblib']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.functions import col\n",
    "import snowflake.snowpark.functions as F\n",
    "advertising_df = session.table('ADVERTISING')\n",
    "predicted_sales_df = advertising_df.select(\n",
    "    col('TV'),\n",
    "    col('RADIO'),\n",
    "    col('NEWSPAPER'),\n",
    "    F.call_udf('predict_sales', col('TV'), col('RADIO'), col('NEWSPAPER')).alias('PREDICTED_SALES')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "|\"TV\"   |\"RADIO\"  |\"NEWSPAPER\"  |\"PREDICTED_SALES\"   |\n",
      "------------------------------------------------------\n",
      "|230.1  |37.8     |69.2         |21.886417875690817  |\n",
      "|44.5   |39.3     |45.1         |10.372262452131155  |\n",
      "|17.2   |45.9     |69.3         |9.113870015216659   |\n",
      "|151.5  |41.3     |58.5         |18.388258741022366  |\n",
      "|180.8  |10.8     |58.4         |16.125779196227914  |\n",
      "|8.7    |48.9     |75.0         |8.805982700924098   |\n",
      "|57.5   |32.8     |23.5         |10.576290497207951  |\n",
      "|120.2  |19.6     |11.6         |13.689984286660831  |\n",
      "|8.6    |2.1      |1.0          |5.743650332055633   |\n",
      "|199.8  |2.6      |21.2         |16.197702901058705  |\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warehouse COMPUTE_WH has been suspended successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    current_warehouse = session.get_current_warehouse()\n",
    "    session.sql(\n",
    "        f\"ALTER WAREHOUSE {current_warehouse[1:-1]} SUSPEND\"\n",
    "    ).collect()\n",
    "    print(f'Warehouse {current_warehouse[1:-1]} has been suspended successfully.')\n",
    "except Exception as e:\n",
    "    print(f'Error suspending the warehouse: {e}')\n",
    "finally:\n",
    "    session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
